{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-02T16:16:25.084718Z","iopub.execute_input":"2022-02-02T16:16:25.085139Z","iopub.status.idle":"2022-02-02T16:16:32.271679Z","shell.execute_reply.started":"2022-02-02T16:16:25.085110Z","shell.execute_reply":"2022-02-02T16:16:32.270929Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Import and Initialize Tokenzier and Model","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer,AutoModelForSeq2SeqLM","metadata":{"execution":{"iopub.status.busy":"2022-02-02T16:17:32.363546Z","iopub.execute_input":"2022-02-02T16:17:32.364060Z","iopub.status.idle":"2022-02-02T16:17:32.368063Z","shell.execute_reply.started":"2022-02-02T16:17:32.364022Z","shell.execute_reply":"2022-02-02T16:17:32.367214Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"allenai/macaw-large\")","metadata":{"execution":{"iopub.status.busy":"2022-02-02T16:18:14.851838Z","iopub.execute_input":"2022-02-02T16:18:14.852128Z","iopub.status.idle":"2022-02-02T16:18:22.759857Z","shell.execute_reply.started":"2022-02-02T16:18:14.852098Z","shell.execute_reply":"2022-02-02T16:18:22.758967Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/macaw-large\")","metadata":{"execution":{"iopub.status.busy":"2022-02-02T16:20:36.365387Z","iopub.execute_input":"2022-02-02T16:20:36.365672Z","iopub.status.idle":"2022-02-02T16:23:11.385147Z","shell.execute_reply.started":"2022-02-02T16:20:36.365644Z","shell.execute_reply":"2022-02-02T16:23:11.383996Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Macaw takes multiple inputs for question,answer,context etc and also can take Angles Q to A , A to Q","metadata":{}},{"cell_type":"code","source":"input_string = \" $answer$ ; $mcoptions$ ; $question$ = What is the difference between cat and dog?\" ","metadata":{"execution":{"iopub.status.busy":"2022-02-02T16:23:38.996397Z","iopub.execute_input":"2022-02-02T16:23:38.996791Z","iopub.status.idle":"2022-02-02T16:23:39.002669Z","shell.execute_reply.started":"2022-02-02T16:23:38.996749Z","shell.execute_reply":"2022-02-02T16:23:39.001816Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"input_ids = tokenizer.encode(input_string, return_tensors=\"pt\")\n","metadata":{"execution":{"iopub.status.busy":"2022-02-02T16:24:38.669085Z","iopub.execute_input":"2022-02-02T16:24:38.670215Z","iopub.status.idle":"2022-02-02T16:24:38.683389Z","shell.execute_reply.started":"2022-02-02T16:24:38.670167Z","shell.execute_reply":"2022-02-02T16:24:38.682557Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"output = model.generate(input_ids,max_length = 200)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T16:25:53.574044Z","iopub.execute_input":"2022-02-02T16:25:53.574679Z","iopub.status.idle":"2022-02-02T16:25:57.131478Z","shell.execute_reply.started":"2022-02-02T16:25:53.574644Z","shell.execute_reply":"2022-02-02T16:25:57.130751Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Our Answer","metadata":{}},{"cell_type":"code","source":"tokenizer.batch_decode(output,skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T16:26:51.829958Z","iopub.execute_input":"2022-02-02T16:26:51.830261Z","iopub.status.idle":"2022-02-02T16:26:51.840087Z","shell.execute_reply.started":"2022-02-02T16:26:51.830227Z","shell.execute_reply":"2022-02-02T16:26:51.839158Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"Another Example","metadata":{}},{"cell_type":"code","source":"input_string = \" $answer$ = A transformer is a deep learning model that adopts the mechanism of self-attention, differentially weighting the significance of each part of the input data. It is used primarily in the field of natural language processing (NLP)[1] and in computer vision (CV).[2] \\\nLike recurrent neural networks (RNNs), transformers are designed to handle sequential input data, such as natural language, for tasks such as translation and text summarization. However, unlike RNNs, transformers do not necessarily process the data in order. Rather, the attention mechanism provides context for any position in the input sequence. For example, if the input data is a natural language sentence, the transformer does not need to process the beginning of the sentence before the end. Rather, it identifies the context that confers meaning to each word in the sentence. This feature allows for more parallelization than RNNs and therefore reduces training times ; $mcoptions$ ; $question$\" ","metadata":{"execution":{"iopub.status.busy":"2022-02-02T16:30:34.665746Z","iopub.execute_input":"2022-02-02T16:30:34.666027Z","iopub.status.idle":"2022-02-02T16:30:34.669371Z","shell.execute_reply.started":"2022-02-02T16:30:34.665990Z","shell.execute_reply":"2022-02-02T16:30:34.668860Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"input_ids = tokenizer.encode(input_string, return_tensors=\"pt\")\n","metadata":{"execution":{"iopub.status.busy":"2022-02-02T16:30:38.278498Z","iopub.execute_input":"2022-02-02T16:30:38.278972Z","iopub.status.idle":"2022-02-02T16:30:38.287352Z","shell.execute_reply.started":"2022-02-02T16:30:38.278930Z","shell.execute_reply":"2022-02-02T16:30:38.286566Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"output = model.generate(input_ids,max_length = 200)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T16:30:41.647776Z","iopub.execute_input":"2022-02-02T16:30:41.648597Z","iopub.status.idle":"2022-02-02T16:30:55.394689Z","shell.execute_reply.started":"2022-02-02T16:30:41.648549Z","shell.execute_reply":"2022-02-02T16:30:55.393736Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"tokenizer.batch_decode(output,skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T16:31:12.383563Z","iopub.execute_input":"2022-02-02T16:31:12.383851Z","iopub.status.idle":"2022-02-02T16:31:12.389984Z","shell.execute_reply.started":"2022-02-02T16:31:12.383819Z","shell.execute_reply":"2022-02-02T16:31:12.389263Z"},"trusted":true},"execution_count":21,"outputs":[]}]}